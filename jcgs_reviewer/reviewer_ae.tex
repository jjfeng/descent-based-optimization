\documentclass[]{article}
\usepackage{amsmath}
\usepackage{color}
\usepackage{graphicx}

\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

\newcommand{\overall}[1]{\textcolor{blue}{#1}}

\newcommand{\point}[1]{\item \textcolor{blue}{#1}}
\newcommand{\reply}{\item[]\ }

\title{Response to Associate Editor}

\begin{document}
	\maketitle
		
	We appreciate the helpful feedback from the reviewer. We have addressed your questions and comments. Below we give a point-by-point response to each of the questions:
		
	\begin{enumerate}
		\point{The authors provided insufficient justification for using a large number of regularization parameters}

		\reply  We have updated the introduction with more examples of problems with multiple regularization parameters. We inserted the following paragraph into Section 1:
		
		\begin{quote}
			In recent years, there has been much interest in combining regularization methods to produce models with multiple desired characteristics. For example, the elastic net (Zou \& Hastie 2003) combines the lasso and ridge penalties; and the sparse group lasso (Simon et al. 2013) combines the group lasso and lasso penalties. In Bayesian regression, a popular method for pruning irrelevant features is to use automatic relevance determination, which associates each feature with a separate regularization parameter (Neal 1996). Finally, neural networks commonly use regularization to control the weights at each node. Snoek et al. (2012) showed that using separate regularization parameters for each layer in a neural network can improve performance. From a theoretical viewpoint, multiple regularization parameters are required in certain cases to achieve oracle convergence rates. van de Geer \& Muro (2014) showed that when fitting additive models with varying levels of smoothness, the penalty parameter should be lower for more ``wiggly'' functions and vice versa. 
		\end{quote}
		
		\point{Some important details have been omitted from the empirical results. Full reproducibility is expected.}
		
		\reply We apologize for omitting some simulation details. We included the number of simulation runs used in Section 3. We also specify the parameters used in the gradient descent procedure in Section 2.5. \textcolor{red}{Can we put up our code somewhere?}
		
		\point{The empirical results cover a relatively small range of scenarios}
		
		\reply We have also included a new, very different, example illustrating the application of our ideas to matrix completion. This example moves away from the simple regression framework and considers matrix-valued data with partially observed entries (and an assumed low-rank structure). The problem now involves minimizing a penalized loss function with a nuclear norm penalty. This joint optimization problem has a much more complex differentiable space compared to the other examples. We had to rely on different representations of this differentiable space in order to (1) show that the conditions of Theorem 1 were satisfied and (2) calculate the gradient. 
		
		The new sections are as follows. Section 2.4.4 introduces low-rank matrix completion and illustrates how to transform the joint optimization problem into an equivalent smooth joint optimization problem. Section 3.4 provides simulation results. Section A.3.4 in the Appendix provides more details on how to calculate the gradient and shows the conditions in Theorem 1 are satisfied. 
		
		
		\point{The technical conditions seem quite restrictive from a practical point of view, and need further explanation/justification (or weakening).}
		
		\reply We apologize for the confusion regarding the technical conditions. Reviewer 2 was concerned that our paper would not be applicable to high-dimensional problems since we had previously specified that the objective function must be strictly convex. Reviewer 2 is correct that our paper does not actually need the strict convexity assumption. We have removed this from the text. Our results only depend on the conditions specified in Theorem 1. 
		
		The most restrictive condition is probably Condition 1, which requires that the local optimality space is also a differentiable space. In our paper, we showed that this condition is likely to hold for the lasso, group lasso, and nuclear norm penalty. We hypothesize that the condition is likely to hold more generally for non-smooth convex penalties. If we think of the penalized problem in its constrained form, the solution is the minimizer of unpenalized loss function that lies in the constraint region. For non-smooth penalty functions, the constraint region has many edges and corners; thus the constrained minimizer is likely to occur at a these non-smooth regions. Since the constrained minimizer perturbs continuously with respect to the penalty parameters, it will likely remain on the same edge/corner. As long as we remain on the same edge/corner, the optimality space and the differentiable space both stay the same and they are likely equal.
		
		\point{Make sure to provide all code for all experiments}
		
		\reply We have included all the code for our experiments. In addition, we plan to make our code fully available on Github. \textcolor{red}{we should make it available and say where the repo is}
		
		\point{They state in the abstract and in the paper: "For many penalized regression problems, the validation loss is actually smooth almost-everywhere with respect to the penalty parameters."  I assume that almost everywhere means "almost everywhere with respect to Lebesgue measure."  But of course, this same statement is true of the objective itself, for which gradient descent cannot be used.  The relevant condition seems to be to be whether the loss is smooth almost everywhere with respect to the probability measure induced by the true sampling model, which is not the case for e.g. lasso/group lasso/etc.  Can the authors please clarify and elaborate on this point?}
		
		\reply 	
		We agree that the condition of interest is whether the loss is smooth almost everywhere with respect to the probability measure induced by the true sampling model. We suspect that the set of knots, the penalty parameters at which the validation loss is not differentiable, has measure zero under the true sampling model. We address this question empirically using a simulation study.
		We solve a penalized least squares problem with a lasso penalty and tuned the penalty parameter to minimize the loss on a separate validation set. In our 500 simulation runs, the penalty parameter that minimized the validation loss was never located at a knot. More specifically, using a homotopy solver for the lasso, we were able to find the \emph{exact} knots, and these points never achieved the minimum value. While this is not definitive proof, we believe it is a strong indication that it is unlikely for solutions to occur regularly at knots in penalized problems.
		
		\textbf{Simulation settings} We ran the simulation 500 times. We considered a linear model with 100 covariates. The training and validation sets included 40 and 30 observations, respectively. The response was generated data from the model
		$$
		y = X\beta + \sigma\epsilon
		$$
		where $\beta = (1, 1, 1, 0, ..., 0)$. $\epsilon$ and $X$ were generated from a standard Gaussian distribution. $\sigma$ was chosen so that the signal to noise ratio was 2. We fit models that minimized the penalized training criterion
		$$
		\hat{\beta}(\lambda) = \arg\min_{\beta} \| y - X\beta \|_T^2 + \lambda \|\beta\|_1
		$$
%		As shown in the Figure \ref{fig:lasso}, the regularization parameter at each iteration is rarely exactly at the knots in the lasso path.
		
%		\begin{figure}
%			\label{fig:lasso}
%			\caption{Histogram of the closest distance between the $\hat\lambda$ and a knot along the lasso path}
%			\centering
%			\includegraphics[width=0.7\textwidth]{lasso_knot_locations.png}
%		\end{figure}
	\end{enumerate}
\end{document}
